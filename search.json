[{"title":"ML2022-Lecture1-Notes","url":"/%E5%AD%A6%E4%B9%A0/NTU-ML-2022/ML2022-Lecture1-Notes/","content":"课程网站\nWhat is Machine Learning?\n\nMachine Learning ≈ Looking for Function\n\nDifferent types\n\nRegression(回归): 输出要预测的数值\nClassification(分类): 输出给定的options中的某一个\nStructured Learing: 创造有结构的物件(作图,写文章)\n\n从最基本的Linear Model开始\n例: 预测youtube频道第二天播放量\n\n构建模型\n基本术语:\n\nmodel: 带有未知参数的函数, 这里就是y=b+wx1y = b + wx_1y=b+wx1​\nfeature: x1x_1x1​, 已知的数据\nweight, bias: 分别是www和bbb\n\n定义损失函数\n一般可以表示为:\nL=1N∑nenL = \\frac{1}{N}\\sum_{n}e_n\nL=N1​n∑​en​\n其中e代表每组数据预测值跟真实值的误差, e可以有不同的计算方法, 如MAE/MSE等。\nError Surface\n测试不同的参数后画出的Loss的等高线图\n\n最优化(optimization)\n梯度下降(gradient descent)\n\n随机挑选初始值w0,b0w^0,b^0w0,b0\n更新参数:\n\nw1←w0−η∂L∂w∣w=w0,b=b0b1←b0−η∂L∂b∣w=w0,b=b0\\begin{align*} w^1 &amp;\\leftarrow w^0 - \\eta \\left. \\frac{\\partial L}{\\partial w} \\right|_{w=w^0, b=b^0} \\\\ b^1 &amp;\\leftarrow b^0 - \\eta \\left. \\frac{\\partial L}{\\partial b} \\right|_{w=w^0, b=b^0} \\end{align*}\nw1b1​←w0−η∂w∂L​​w=w0,b=b0​←b0−η∂b∂L​​w=w0,b=b0​​\n\n迭代\n\n其中η\\etaη就是学习率(learning rate), 一般要手动设定。\n我们把ML中需要手动设定的参数称为hyperparameter\n问题: 局部最优解(local minima) (?)\n\n并非真正的难题\n更加复杂的model\n关于激活函数\n\n大部分复杂的函数图像理论上都可以使用大量的蓝色折线图叠加来表达\n但是我们又该怎么表示这个「蓝色的折线图」呢?\n🤓☝️我们有sigmoid函数\ny=c11+e−(b+wx1)=c sigmoid(b+wx1)\\begin{align*} y &amp;= c \\frac{1}{1 + e^{-(b + wx_1)}} \\\\ &amp;= c\\,sigmoid(b + wx_1) \\end{align*}\ny​=c1+e−(b+wx1​)1​=csigmoid(b+wx1​)​\n而实际上这条「蓝色的折线图」就通常被称为「Hard Sigmoid」\n改变参数对图像的影响:\n\n除了sigmoid函数, 我们还可以用ReLU函数:\n\n那么对于这样的sigmoid函数或者ReLU函数或者其他的函数, 我们就将其称为激活函数。\n以下我们基于使用sigmoid函数的情况。\nNeural Network\n对于一组feature, 我们有:\ny=b+∑ici sigmoid(bi+wix1)y = b + \\sum_{i}c_i\\,sigmoid(b_i + w_ix_1)\ny=b+i∑​ci​sigmoid(bi​+wi​x1​)\n如果我们想要同时考虑 jjj 组feature:\ny=b+∑ici sigmoid(bi+∑jwijxj)y = b + \\sum_{i}c_i\\,sigmoid(b_i + \\sum_{j}w_{ij}x_{j})\ny=b+i∑​ci​sigmoid(bi​+j∑​wij​xj​)\n我们引入线性代数中向量与矩阵的概念来简便地表示y:\n\n然后我们把a1,a2,...a_1,a_2,...a1​,a2​,...继续作为新的xxx, 引入更多未知的参数来让函数更复杂:\n\n然后我们就有了Neural Network (:\n\n\n为什么不在一层上增加更多的节点让网络「变宽」而是要多做几层让网络「变深」?\n以后再讲(((\n(后续可能会补链接)\n\n\n为什么不能一直增加深度?\n容易带来过拟合的问题: 在训练集上表现变好但在未知数据上表现变差\n\n\n","categories":["学习","NTU-ML-2022"],"tags":["Notes","AI"]},{"title":"解决AttributeError Can't get attribute on module","url":"/%E6%8A%80%E6%9C%AF/%E6%9D%82%E9%A1%B9/%E8%A7%A3%E5%86%B3AttributeError%20Can't%20get%20attribute%20on%20module/","content":"之前本地跑大作业时遇上的神秘问题，有点抽象，遂记录一下。\n问题\n本地跑大作业的模型训练时一直卡着不动，看jupyter命令行发现报错:AttributeError: Can't get attribute 'FashionDataset' on &lt;module '__main__' (&lt;class '_frozen_importlib.BuiltinImporter'&gt;)&gt;\n在网上搜索一番后在这篇文章发现了问题原因:\n\n实际上这个地方：在linux中使用的是fork的方式，可以复制公共变量和方法到新开启的进程中，但是windows中是重建一个新的进程(全新)，在进程中并不存在公共的变量和方法，所以会出现这个问题，未能导入模块中定义的对象\n\n解决\n把出问题的代码(我这里是FashionDataset类)打包成一个单独的.py文件再import进来就行。\n# dataset.pyimport osimport gzipimport numpy as npimport torchfrom torch.utils.data import Datasetclass FashionDataset(Dataset):    def __init__(self, datadir, transform, is_train=True):        super().__init__()        self.datadir = datadir        self.transform = transform        self.img, self.label = self.load_data(datadir, is_train)        self.len_data = len(self.img)    def __getitem__(self, index):        return self.transform(self.img[index]), self.label[index]    def __len__(self):        return self.len_data    def load_data(self, datadir, is_train):        dirname = os.path.join(datadir)        files = [&#x27;train-labels-idx1-ubyte.gz&#x27;, &#x27;train-images-idx3-ubyte.gz&#x27;,                 &#x27;t10k-labels-idx1-ubyte.gz&#x27;, &#x27;t10k-images-idx3-ubyte.gz&#x27;]        paths = [os.path.join(dirname, f) for f in files]        if is_train:            with gzip.open(paths[0], &#x27;rb&#x27;) as lbpath:                label = np.frombuffer(lbpath.read(), np.uint8, offset=8)            with gzip.open(paths[1], &#x27;rb&#x27;) as imgpath:                img = np.frombuffer(imgpath.read(), np.uint8,                                    offset=16).reshape(len(label), 28, 28)        else:            with gzip.open(paths[2], &#x27;rb&#x27;) as lbpath:                label = np.frombuffer(lbpath.read(), np.uint8, offset=8)            with gzip.open(paths[3], &#x27;rb&#x27;) as imgpath:                img = np.frombuffer(imgpath.read(), np.uint8,                                    offset=16).reshape(len(label), 28, 28)        return img, label\n然后在主文件中from dataset import FashionDataset就行\n","categories":["技术","杂项"],"tags":["bug","Python"]},{"title":"2025-09-14-周日-一周总结","url":"/%E7%94%9F%E6%B4%BB/%E5%91%A8%E8%AE%B0/2025-09-14-%E5%91%A8%E6%97%A5-%E4%B8%80%E5%91%A8%E6%80%BB%E7%BB%93/","content":"过去一周总结\n也是在摆了一个暑假后重新开始写周记了，既然连奶龙同学现在都能坚持日更那我肯定是要坚持周更了。\n开学第一周感觉大多数课也都没上啥实质性的内容，然后在经历了暑假编程集训和数模国赛的拷打以后这一周也基本上是摆过去了，而且在周五开始感冒，更是天崩开局。\n不过还是可以搞一个锐评大二上课程第一印象从夯到拉的:\n\nAI数学基础：课没什么问题，老师也没什么问题，可能最大的问题是我数学太拉，综合给到人上人。\n数据结构：夯。窦老师很能活跃班级气氛而且讲的非常深入浅出，给的思考题也很有趣，真神。\n区块链：个性化选修课，目前来看可能也比较偏向通识课，不会讲一些太深的东西，内容本身还是比较有趣的，第一节课甚至花了小半节课来讲中本聪野史（）。综合给个人上人。\nAI引论：课的内容看上去覆盖面很广也比较有趣，第一周作业居然是给一个小故事生成AI视频，老师也很有亲和力，综合可以给到顶级。\n概统：前两节课讲的基本都是高中时期的内容，而且正好卡在下午最容易昏睡的时间点，不过看前人的评价好像还不错，我现在还不好评价，先给到一个人上人。\nICS：本来想给到夯的，因为助教活人感确实强而且准备的资料（包括作业之类的）确实能感觉出来很用心，甚至还专门搞了个答疑论坛用来课程答疑。结果什么叫第一周因为讲前几章的老师有事所以我们直接从第六章开始讲？那岂不是意味着国庆就有很大的可能要直接开做cache lab？那种事情不要啊。而且这老师讲话语速快的就离谱，感觉像词烫嘴。那最后只能先给到顶级，看看后面情况了。\n英语演讲：老师一眼好，事一眼多，对冲一下给到人上人。\n游泳：夯。首先是学校游泳馆设施就很不错而且水质也好，远超于我暑假里去游的露天游泳池，至少里面不会随机刷新树叶或者虫子；其次是老师也很专业很有趣；最后是不仅可以提前一点跑路还能顺带解决当天的洗澡问题。唯一的问题是人比较多游起来要小心点。\n马原、膝盖：没啥说的，这俩一个拉一个入机。唯一的区别在于膝盖第一周没布置作业而马原居然已经布置了一篇小论文，我真没招了。\n\n等到大二上结束的时候再回来看看，希望没有什么回旋镖。\n\n未来一周展望\n下周就可以步入正轨了，大二上一定好好努力！\n首先得想办法给小论文水掉😅难绷了。\n然后备战一下9月21号的CSP吧，这次争取再进步个十几二十分。\n\n","categories":["生活","周记"]},{"title":"2025-09-21-周日-一周总结","url":"/%E7%94%9F%E6%B4%BB/%E5%91%A8%E8%AE%B0/2025-09-21-%E5%91%A8%E6%97%A5-%E4%B8%80%E5%91%A8%E6%80%BB%E7%BB%93/","content":"过去一周总结\nCSP大败而归了，12月再战。\n最近的身体状况不是很好，这周头上感冒刚好，之前拔智齿的拔牙窝附近又开始痛，似乎是牙槽骨凸出来了一块，给牙龈和旁边的舌头顶坏了，参看这个知乎问题，不过到目前写文章的时候已经不怎么痛了。\n总之这一周的情况就是感觉很累但也不知道累什么，跟身体的情况可能也有一点关系，不过好歹学校的作业是完成的差不多了，除了下周英语演讲课要做的自我介绍还没有什么头绪。\n周六一天说是准备CSP实际也不知道要准备啥，毕竟算法基础太薄弱了临时抱佛脚用处也有限，遂打游戏，给鸣潮一堆活动做掉了然后抽了个夏空来补完整卡提配队。\n考完CSP出来，看到优秀学长（存疑）牢记发表的文章入土了才是上岸了，顿时又释然了。在海里扑腾的人不一定要上岸，不淹死就行了。\n提到了牢记就能顺便提一下目前关注的优质个人自媒体博主：躺刑记诉四大金刚（躺平学原理、刑法学爱好者（公众号已改名TENET.INKER）、记之而去、此处不宜诉讼），构成了我对当下时政热点的大部分信息和观点来源。有时候也挺羡慕这些学文科的写文章表达观点就像呼吸一样自然，而我每周的周记都得憋一会，还憋不出来多少个字。\n\n未来一周展望\n下周数据结构和AI引论都要开始上机了，周中应该会变得更忙。更难绷的是周末又要调休还调的是周二的课，这天除了没早八基本上要一直上到晚上。而这也就意味着这个九月一共四个周末：第一个周末在被国赛拷打；第二个周末在被感冒拷打；这个周末被CSP拷打；下个周末被调休拷打。这是在干什么，就不能让我有一个正常的周末吗（恼）。\n总而言之首要目标是活到国庆，顺便打下周的崩铁更新以及084×粥联动。\n\n","categories":["生活","周记"]},{"title":"2025-09-28-周日-一周总结","url":"/%E7%94%9F%E6%B4%BB/%E5%91%A8%E8%AE%B0/2025-09-28-%E5%91%A8%E6%97%A5-%E4%B8%80%E5%91%A8%E6%80%BB%E7%BB%93/","content":"过去一周总结\n首先严格来说写这篇周记的时间已经是周一了，这是因为调休导致忘记了昨天是周日应当写周记，不过刚刚又想起来了，趁为时未晚赶紧补上。\n上周事情还是非常多的，首先是准备英语演讲的自我介绍，我从高中时期每周挤一个多小时地铁上下学的角度切入讲了一个非常🍬的自嘲式自我介绍，令人忍俊不禁。奶龙同学曾经认为像我高中时期这样不看手机不睡觉挤一个半小时地铁回家会使他变成精神病，侧面证明了这篇自我介绍应该还能算勉强达成「具有新意」的要求。\n然后从周三开始就开始猛攻cache lab，先花了一点时间拿下了partA的cache模拟，接着花了大量的时间在思考partB的优化上，截至目前为止还能暂时性地占据排行榜榜一，不过现在case2和case3的调优都碰上瓶颈了，也不知道还能榜一多久。\n目前的三个大作业：\n数据结构：实现顺序表和单链表两个数据结构，然后基于其中之一搓一堆字符串处理相关的功能。这个基本还没怎么动。\nAI引论：以代码填空的形式完成一个简单的井字棋小游戏，重点是通过alpha-beta剪枝来优化电脑的搜索方式。这个比较简单，很快就做完了。令人难绷的是给的代码模板有一个小bug导致无法选择谁先手，其实是对or运算符的不规范使用导致的。\nICS：没啥要说的了，暂时不会再花更多的时间想case2和case3的更优解了。\n实际上大作业的DDL都在国庆后，而现在已经基本上算是解决了两个，可喜可贺。\n还有你怎么知道我崩铁一次不歪拿下11长夜月，以及084两百抽出二井一成功集齐联动EGO🥳\n\n未来一周展望\n先想办法给最麻烦的数据结构大作业写了，然后等国庆回去再把英语演讲要求拍的视频拍了，剩下的时间就都可以用来干别的事了。至于具体要干什么还没怎么想好，等放假了慢慢想。\n\n","categories":["生活","周记"]},{"title":"2025-10-05-周日-一周总结","url":"/%E7%94%9F%E6%B4%BB/%E5%91%A8%E8%AE%B0/2025-10-05-%E5%91%A8%E6%97%A5-%E4%B8%80%E5%91%A8%E6%80%BB%E7%BB%93/","content":"过去一周总结\n成功在放假前解决了数据结构大作业1: 使用单链表实现一些对字符串的基础操作(事实上底层逻辑也就是实现一些链表基础操作，例如反转链表和判断回文链表等等)。看上去比较麻烦但上手了之后就发现实际上也没有很难的部分，主要还是大一下的时候没怎么写C导致现在不是很熟练。\n国庆放假到家的那一天突然灵光一现开始改cache lab最终依靠暴力循环展开胜天半子，结果最后发现没连校园网传不上去评测结果🤡，现在cache lab榜单也处于一个暗流涌动的状态，等国庆结束大家都回学校了指不定会有多少小惊喜()。\n然后就开始纯纯摆，除了作息稍微阳间了一点还有每天早上为了应对10月份的体测绕着小区跑1km，剩下的大部分时间其实都在打游戏和刷B站中度过了。以及愈发的感觉到也许应该培养睡午觉的习惯，因为现在中午即使是在做打游戏这种强刺激性的事情时也容易感到困倦。\n顺便，国庆的时候复健了一下音游，然后被phi和mai的联动包移交蔡司了。4K更是下滑了一个大段，从8dan掉回7dan了。然而练音游实际上需要占用的时间并不少，而且不练以后状态下滑很快，我也没法保证以后还有这么多时间能打音游，所以也许这辈子就这样了(悲)。\n\n未来一周展望\n7号可能要团建，8号回北京，那么国庆剩下的时间实际上也没有多少了，先把9月学的东西复习一下，资料整理一下吧。至于cache lab的报告倒是不急，万一回去的时候又灵光一现了呢（又幻想了）。\n然后还有沟槽的马原pre，第一节课本来说的是交一个2000字小论文，后来老师又说「鼓励pre」，然后就逐渐演变成了现在的「不pre不行」的态势，我真的没招了。目前的进度基本上为0，但是又考虑到后面只会越来越忙，还不如赶紧搞掉以免夜长梦多。\n然后其实就不太清楚还要干什么了，走一步看一步吧。值得一提的是9月24日的时候填报了科研导师的选择志愿，算算时间应该结果也快出来了，也许可以重新启动一下李宏毅来进行一个热身。\n\n","categories":["生活","周记"]},{"title":"建站记录","url":"/%E5%AD%A6%E4%B9%A0/%E5%BB%BA%E7%AB%99/%E5%BB%BA%E7%AB%99%E8%AE%B0%E5%BD%95/","content":"参考:\nObsidian + Hexo + Github Pages建站\nHexo\nObsidian+Git完美维护Hexo博客\n支持渲染双向链接:\nHexo 博客适配 Obsidian 新语法\n图床配置\n腾讯云对象存储COS自建图床并配置Obsidian自动上传\nNext主题配置\nNext\n","categories":["学习","建站"],"tags":["Obsidian","Hexo"]},{"title":"2025-10-12-周日-一周总结","url":"/%E7%94%9F%E6%B4%BB/%E5%91%A8%E8%AE%B0/2025-10-12-%E5%91%A8%E6%97%A5-%E4%B8%80%E5%91%A8%E6%80%BB%E7%BB%93/","content":"过去一周总结\n中秋节吃到了「云腿月饼」，以前从来没吃过第一次吃感觉味道还蛮好的，很适合我这种喜欢吃咸甜口的人。\n7号进行了6人剧本杀团建，打了「死者从幻夜中醒来」这个本子，其实个人感觉体验差强人意。文笔可以，叙诡写的确实比较好，前半部分打起来也比较丝滑，但是后半部分确实有点牢了，而且我个人本来就不太喜欢盘这种家族伦理关系。不过最后的立意还算好(大概?)，甚至还有点反战的元素在里面，升华这一块👍。\n回北京以后差点没被冻似，然后开学第一天就是接近满课，这两天的课还又布置了一堆作业，纯纯不当人。昨天写掉了cache lab的报告，人脑模拟cache手算miss算的天昏地暗，算到一半还突然灵光一现又回去改代码，报告写完的时候整个人已经燃尽了。今天在机房坐了一个下午把大部分的作业都写了，等我写完这个周记晚上回去直接先爽玩再追番😋\n然后这一周游戏上原和铁都在长草，粥的新主线还没打，就推了一下鸣的2.7新主线，也算是平稳落地吧，可以等3.0了。4K复健的成果是蓝顶95.8，ultimate dream96，月哀月夜和月亮门都大概93~94，感觉自己正在往乱比和切比的方向发展，坏处就是叠已经完全不会打了，机械少女只能91了😭\n\n未来一周展望\n首先是很遗憾这一周马原pre的进度仍然为0，下周一定(\n更难绷的是这个pre还没搞掉膝盖那边又已经分完组布置pre了，这个分组甚至不是自由组队，还好他分组是按照专业分的，熟人比较多。\n然后英语演讲要准备两个informative speech的选题也还没有什么头绪。\n下周cache lab结束以后直接无缝衔接data lab，这下爽了。但好像我们的data lab是通过性的，也就是说不用卷压op打榜了，win🤩\n其次就是下周可能要开始着手期中考的复习之类的了，至于李宏毅ML，我祝他好运()\n不过这个分导师的结果也是迟迟不出，不知道得等到啥时候。\n\n","categories":["生活","周记"]},{"title":"2025-10-19-周日-一周总结","url":"/%E7%94%9F%E6%B4%BB/%E5%91%A8%E8%AE%B0/2025-10-19-%E5%91%A8%E6%97%A5-%E4%B8%80%E5%91%A8%E6%80%BB%E7%BB%93/","content":"过去一周总结\n这周效率体感上比上周要高一些，也是基本上把大大小小的作业写的差不多了，周三ics布置的datalab花了一节周三晚上上机课加上周六在机房半个下午直接拿下了，做完cache再来做这个实在是没什么感觉，但是仍然在一些题(例如i2f)实现上卡了一会，有点🍬了。\n然后数模国赛一不小心打进国奖了。不到一个月之前在科研领航启动会上听某个科研大佬学姐做经验分享时听到她说自己「一不小心拿了个国一」还觉得「这家伙在说什么呢」，事实证明这种比赛拿奖还真就是「一不小心」的事，感觉随着AI继续发展以后这种比赛的含金量还会降低。也许后面可以整理一下这次经历写一个游记，我先立一个flag在这里。\n周末把前半学期的各种资料全部都整理了一下，下周要正式进入期中复习阶段了。感觉最难搞的还是这个AI数学基础，貌似这个课每年都在变，前人流传下来的东西也不一定全，又没有什么考题能让我拟合一下，后面再想想办法吧。\n今天去了2025上海新生见面会，白嫖到了神秘小零食，但遗憾的是没有见到25级信高的新生，显然别人并不像我一样周末都那么无所事事。\n顺便，在写完上周的周记以后回寝室开了两把音游，然后就过9dan了，爆种这种事情确实是可遇不可求啊！但是现在10dan遇到了一个十分尴尬的情况，就是一开始打的时候叠打不好，练了几天叠终于打好了乱又没手感了😅，不知道何时能够常规毕业呢？\n\n未来一周展望\n根据我最近正在实践的「四象限法」清单中的相关内容，下周我需要完成的「重要且紧急」的事情有:\n\n周四前完成英语演讲的准备，类型为「informative speech」，我最终选择的主题为「bitcoin」，是时候上演「赌狗笑传之炒炒币」了。\n完成AI引论lab4(k-means聚类)的实验报告\n完成datalab的实验报告\n\n下周六年级有团建安排，可以预见的是周六一天都不会有任何进展，这就对周中的效率提出了更高的要求。祈祷下周别再来大作业了，虽然数据结构很可能又要布置大作业了(悲)。\n\n","categories":["生活","周记"]},{"title":"test","url":"/%E5%AD%A6%E4%B9%A0/%E5%BB%BA%E7%AB%99/test/","content":"hello, world!\n\n建站记录\nLaTeX\\LaTeXLATE​X\n","categories":["学习","建站"]},{"title":"2025-10-26-周日-一周总结","url":"/%E7%94%9F%E6%B4%BB/%E5%91%A8%E8%AE%B0/2025-10-26-%E5%91%A8%E6%97%A5-%E4%B8%80%E5%91%A8%E6%80%BB%E7%BB%93/","content":"过去一周总结\n又是猛猛写作业的一周。具体来说，本周完成了:\n\nAI引论lab4报告\ndatalab报告\nAI数学作业5\nICS作业4\n概率论作业5\nAI引论lab5\n英语演讲稿子\n已经燃尽了。然后今天演练了一遍演讲发现4分钟根本讲不完，后面稿子还要改🤡。\n\n周六前往了「天津」进行了年级团建活动。在前往天津的高铁上我的前座坐了一位83岁的老爷子，他的车票好像出了点问题然后一直在跟乘务抱怨那个卖票机器，中间还随口说了一句说「现在搞的什么AI都是骗老百姓的」，然后旁边一堆AI专业的直接憋笑(我也在憋)，不过人家口才真的不错说话跟说书一样抑扬顿挫，表达能力已经远超于我。上午参观天大，印象最深刻的是天大的水体丰富程度纯纯薄纱尼禄，一个湖感觉100个一勺池都不够装的。下午去张园，然后发现没啥看的，拍完集体照过一会就润了去五大道进行一个逛，晚饭在「宋记老房子」吃了一顿，他家「酸辣土豆丝」和「熏排骨」都挺不错的，结果津菜一大特色的「八珍豆腐」吃起来反倒感觉一般。最终结算步数26752，直接成为脚痛大学学生()\n以及这一周导师分配结果终于出来了，联系上导师以后直接让我先来跟着听组会，但我怀疑我现在这水平听组会除了有概率蹭到饭其他的到底能学到多少实在是不好说。依然继续沉淀！\n游戏上直接把崩铁删除了，这byd策划吃相是越来越难看了，正好我也玩不太动了放着还占空间，直接删了最清净。然后预下载了二重螺旋到时候尝尝咸淡，不过就目前看来还是有点草台班子了。音游回坑了osu!mania，涨了点pp，但实力依旧远低于打移动端malody，电脑打4K体验确实和pad迥异，还要适应一下。\n\n未来一周展望\n下周目标比较明确，基本就是:\n\n准备周四英语演讲，做PPT\n做数据结构恐怖「HTML解析」大作业\n复习AI数学，准备期中考\n提前跑两天步，准备体测\n这大二上事情真是太多了，基本上每周都有一堆各种各样的作业，还有一些杂七杂八的事情，有点变态。以及听到有认识的只比我岁数略大一点的远房亲戚(?)视网膜脱落了，愈发感觉身体健康的重要性，也是需要好好调整一下作息了。\n\n\n","categories":["生活","周记"]}]